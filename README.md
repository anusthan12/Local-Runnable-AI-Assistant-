# Local AI Assistant with Retrieval Augmented Generation (RAG)

## Introduction
This project focuses on the development of a locally runnable AI Assistant empowered by open-source Large Language Models (LLMs) and Retrieval Augmented Generation (RAG). Leveraging Python's LangChain framework, our AI Assistant operates directly on the user's system, ensuring data privacy. Equipped with capabilities including question answering, database access, coding assistance, and more, our AI Assistant showcases the potential of open-source models and RAG to offer secure and versatile solutions for various industries.



https://github.com/anusthan12/Local-Runnable-AI-Assistant-/assets/102304867/459a7b96-3891-463c-b95e-08a0755f83af



## Problem Statement
While numerous AI Assistants exist online, few are capable of running locally on a user's machine. Existing offline options often suffer from limited capabilities or excessive resource consumption. In response, our project employs Retrieval Augmented Generation and optimized small-sized open-source models to address these challenges.

## Technologies Used
- HTML
- CSS
- JavaScript
- Tailwind CSS
- Bootstrap
- Particle.js
- Python
- LLM
- Machine Learning (ML)
- Gemma

## Advanced Details
### Retrieval Augmented Generation
Retrieval-Augmented Generation (RAG) enhances large language models by incorporating authoritative external knowledge bases, improving output without retraining. With billions of parameters, these models excel at tasks like question answering and language translation. RAG extends these capabilities to specific domains or internal knowledge bases, ensuring relevance and accuracy without additional training costs.

### LangChain
LangChain is an open-source framework for building applications with large language models (LLMs). Offering tools and abstractions, LangChain aids in creating customized, accurate, and relevant information. Developers can utilize LangChain components to create new prompt chains or modify existing templates. Additionally, LangChain enables LLMs to access new data sets without requiring retraining.

## Future Scope
- Enhanced LLM Integration: Exploring modern and fine-tuned LLMs for improved performance.
- Advanced Security Features: Implementing user authentication, data encryption, and secure communication protocols.
- Image Understanding: Adding features to understand and interact based on images provided by the user.

## Conclusion
This project successfully developed a local LLM AI Assistant with Retrieval Augmented Generation (RAG), showcasing the potential of offline AI Assistant applications using open-source tools. With fundamental features such as user interaction, RAG question answering, and local deployment, our AI Assistant offers a glimpse into the future of secure and versatile AI solutions.
